# Image Captioning in Nepali using ViT and GPT-2

## Overview
This project aims to develop an image captioning model that generates captions for images in the Nepali language, combining Vision Transformer (ViT) and GPT-2. The model is trained to understand and describe the content of images in Nepali, providing a useful tool for localization and accessibility.

## Current Status
- **Work in Progress**: The project is actively being developed.

## Dataset
To train and evaluate this model, we are using the Flickr30K dataset. You can download it from [Kaggle](https://www.kaggle.com/datasets).

## Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/iaavas/Image-Captioning-in-Nepali-Transformers.git
   cd Image-Captioning-in-Nepali-Transformers
   ```

2. Set up a virtual environment:
   ```bash
   python3 -m venv venv
   source venv/bin/activate  # On Windows use `venv\Scripts\activate`
   ```

3. Install the required packages:
   ```bash
   pip install -r requirements.txt
   ```

## Contributors
- [Aavash Baral](https://www.github.com/iaavas)
- [Gaurav Pyakurel](https://github.com/gauravpkl1010)
- [Adish Bhattarai](https://github.com/adish2003)

## License
This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---
